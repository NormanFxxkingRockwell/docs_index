{
  "domain": "ai",
  "domain_summary": "AI领域包含MindSpore Lite Kit和Neural Network Runtime Kit两个主要组件，提供端侧AI模型推理、训练和跨芯片推理计算能力，支持图像分类、语音识别、目标检测等多种AI应用场景。",
  "core_concepts": [
    "MindSpore Lite推理引擎",
    "模型转换",
    "端侧训练",
    "Neural Network Runtime",
    "跨芯片推理",
    "张量",
    "N-API封装接口",
    "模型编译与缓存",
    "离线模型推理",
    "算子支持列表"
  ],
  "document_count": 12,
  "documents": [
    {
      "doc_id": "MindSpore-Lite-Kit-Introduction",
      "title": "MindSpore Lite Kit简介",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/MindSpore-Lite-Kit-Introduction.md",
      "summary": "介绍MindSpore Lite Kit的基本信息、使用场景、约束与限制、亮点优势、开发流程和开发方式，帮助开发者快速了解和使用MindSpore Lite进行AI应用开发。",
      "key_topics": ["MindSpore Lite", "AI引擎", "模型推理", "模型训练", "开发流程"]
    },
    {
      "doc_id": "mindspore-lite-converter-guidelines",
      "title": "使用MindSpore Lite进行模型转换",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/mindspore-lite-converter-guidelines.md",
      "summary": "介绍如何使用MindSpore Lite模型转换工具将第三方框架模型转换为.ms格式模型，包括工具获取、环境配置、参数说明和使用示例等。",
      "key_topics": ["模型转换", "ONNX", "CAFFE", "TensorFlow", "离线模型"]
    },
    {
      "doc_id": "mindspore-lite-guidelines",
      "title": "使用MindSpore Lite进行模型推理 (C/C++)",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/mindspore-lite-guidelines.md",
      "summary": "介绍使用MindSpore Lite推理引擎进行模型推理的通用开发流程，包括模型准备、上下文创建、模型加载、输入数据设置、推理执行和结果获取等完整步骤。",
      "key_topics": ["模型推理", "C/C++", "上下文", "张量", "NNRT"]
    },
    {
      "doc_id": "mindspore-lite-train-guidelines",
      "title": "使用MindSpore Lite进行端侧训练 (C/C++)",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/mindspore-lite-train-guidelines.md",
      "summary": "介绍使用MindSpore Lite端侧AI引擎进行模型训练的通用开发流程，包括模型准备、上下文创建、模型加载、训练执行、模型导出和释放等完整步骤。",
      "key_topics": ["端侧训练", "C/C++", "模型导出", "训练配置", "单步训练"]
    },
    {
      "doc_id": "mindspore-guidelines-based-js",
      "title": "使用MindSpore Lite实现图像分类（ArkTS）",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/mindspore-guidelines-based-js.md",
      "summary": "介绍如何使用MindSpore Lite ArkTS API实现图像分类应用，包括模型选择、推理代码编写、图像预处理、模型加载和推理执行等完整开发流程。",
      "key_topics": ["图像分类", "ArkTS", "图像预处理", "相册选择", "推理结果处理"]
    },
    {
      "doc_id": "mindspore-guidelines-based-native",
      "title": "使用MindSpore Lite实现图像分类（C/C++）",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/mindspore-guidelines-based-native.md",
      "summary": "介绍如何使用MindSpore Lite Native API实现图像分类应用，包括模型选择、推理代码编写、N-API封装、图像预处理和推理执行等完整开发流程。",
      "key_topics": ["图像分类", "C/C++", "N-API", "图像预处理", "动态库封装"]
    },
    {
      "doc_id": "mindspore-asr-based-native",
      "title": "使用MindSpore Lite实现语音识别（C/C++）",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/mindspore-asr-based-native.md",
      "summary": "介绍如何使用MindSpore Lite在C/C++中实现语音识别应用，包括环境配置、模型选择、音频播放代码编写、识别代码编写、N-API封装、推理执行和结果处理等完整开发流程。",
      "key_topics": ["语音识别", "C/C++", "音频处理", "Whisper模型", "语音转文本"]
    },
    {
      "doc_id": "mindspore-lite-supported-operators",
      "title": "MindSpore Lite Kit算子支持列表",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/mindspore-lite-supported-operators.md",
      "summary": "列出MindSpore Lite Kit与ONNX Opset18相比所支持的CPU后端算子列表以及对应关系，帮助开发者在转换ONNX模型时确保模型转换成功。",
      "key_topics": ["算子支持", "ONNX", "CPU后端", "算子规格", "模型转换"]
    },
    {
      "doc_id": "mindspore-Readme-CN",
      "title": "MindSpore Lite Kit（昇思推理框架服务）",
      "path": "../../docs/zh-cn/application-dev/ai/mindspore/Readme-CN.md",
      "summary": "MindSpore Lite Kit文档索引，提供MindSpore Lite Kit相关的所有文档链接，包括简介、模型转换、模型部署、图像分类应用、语音识别应用和算子支持列表等。",
      "key_topics": ["文档索引", "MindSpore Lite", "开发指南", "应用示例"]
    },
    {
      "doc_id": "Neural-Network-Runtime-Kit-Introduction",
      "title": "Neural Network Runtime Kit简介",
      "path": "../../docs/zh-cn/application-dev/ai/nnrt/Neural-Network-Runtime-Kit-Introduction.md",
      "summary": "介绍Neural Network Runtime Kit的基本信息、使用场景、架构、亮点特征、能力范围、与其他Kit的关系和模拟器支持情况。",
      "key_topics": ["Neural Network Runtime", "跨芯片推理", "模型编译", "内存管理", "设备管理"]
    },
    {
      "doc_id": "neural-network-runtime-guidelines",
      "title": "Neural Network Runtime对接AI推理框架开发指导",
      "path": "../../docs/zh-cn/application-dev/ai/nnrt/neural-network-runtime-guidelines.md",
      "summary": "介绍如何使用Neural Network Runtime Native接口开发AI推理应用，包括环境准备、接口说明、模型构造、模型编译和推理执行等完整开发流程。",
      "key_topics": ["模型构造", "模型编译", "推理执行", "张量描述", "设备管理"]
    },
    {
      "doc_id": "nnrt-Readme-CN",
      "title": "Neural Network Runtime Kit（Neural Network运行时服务）",
      "path": "../../docs/zh-cn/application-dev/ai/nnrt/Readme-CN.md",
      "summary": "Neural Network Runtime Kit文档索引，提供Neural Network Runtime Kit相关的所有文档链接，包括Kit简介和AI推理框架开发指导等。",
      "key_topics": ["文档索引", "Neural Network Runtime", "开发指导"]
    }
  ]
}